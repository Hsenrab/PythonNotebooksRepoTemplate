{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Simple Demo Notebook\n",
    "\n",
    "This notebook demonstrates all the key concepts and patterns used in this template repository:\n",
    "\n",
    "- ✅ Environment Variables\n",
    "- 🔄 Testing Integration (Phase 5)\n",
    "- 🔒 Azure Authentication (Phase 7)\n",
    "- 📊 Data Analysis Examples\n",
    "\n",
    "Each section shows clean, simple patterns you can copy to your own notebooks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 🔧 Load Environment Variables\n",
    "\n",
    "Environment variables provide a secure way to store configuration values and sensitive information outside of your code, preventing secrets from being committed to version control. They also allow the same code to run in different environments (development, testing, production) without modification, making your notebooks more portable and maintainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get configuration\n",
    "project_name = os.getenv('PROJECT_NAME')\n",
    "\n",
    "\n",
    "print(f\"Project: {project_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 🧪 Testing\n",
    "\n",
    "Testing notebooks ensures your analysis remains valid as dependencies change and catches errors before they reach collaborators or end users. It also serves as living documentation that confirms your code works as expected, improving the reliability and trustworthiness of your data science workflow.\n",
    "\n",
    "This notebook is tested with pytest and nbmake. When you run:\n",
    "\n",
    "```\n",
    "pytest --nbmake .\n",
    "```\n",
    "\n",
    "All notebooks in the repository are executed, and any errors will cause the tests to fail.\n",
    "\n",
    "See `error_demo_notebook.ipynb` for an example of a notebook with a deliberate error that will fail testing.\n",
    "\n",
    "## 🔒 Azure Authentication Demo  \n",
    "\n",
    "*Coming in Phase 7 - will show secure Azure authentication patterns*\n",
    "\n",
    "## 📊 AI Foundry Demo\n",
    "\n",
    "*Coming later - will show connection to AI Foundry with environment configuration*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell demonstrates a successful test\n",
    "print(\"This notebook passes all tests because it contains no errors\")\n",
    "\n",
    "# Simple calculation to demonstrate valid code\n",
    "result = 2 + 2\n",
    "print(f\"2 + 2 = {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 🧹 Git Cleaning for Notebooks\n",
    "\n",
    "When committing notebooks to version control, it's best practice to clear all outputs to keep the repository clean and focused on code rather than results. This:\n",
    "\n",
    "1. Makes diffs and code reviews more meaningful, focusing on actual code changes\n",
    "2. Reduces repository size by eliminating large outputs like images or data tables\n",
    "3. Prevents unintentionally committing sensitive information that might appear in outputs\n",
    "4. Ensures consistent execution environments when others clone the repository\n",
    "\n",
    "This template includes pre-commit hooks to automatically clean notebook outputs before committing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Here is some sensitive data that could accidently be committed in the output\")\n",
    "print(f\"API Key: <loaded from .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 📝 When Git Hooks Run\n",
    "\n",
    "This repository uses two methods to clean notebook outputs:\n",
    "\n",
    "1. **Pre-commit hooks**: These run automatically when you make a `git commit` command, but **not** when you run `git add`. The pre-commit hooks in this repository:\n",
    "   - Remove notebook outputs and metadata (`nbstripout`)\n",
    "   - Fix whitespace and formatting issues\n",
    "   - Check for large files\n",
    "   - Validate YAML files\n",
    "\n",
    "2. **Git filters**: The setup script also installs `nbstripout` as a Git filter using `nbstripout --install`. This configures Git to automatically clean notebook files during the staging process when you run `git add`. \n",
    "\n",
    "This dual approach ensures notebooks are cleaned regardless of whether you use `git add` followed by `git commit` or just `git commit -am \"message\"`.\n",
    "\n",
    "To set up these hooks in your environment, run:\n",
    "```\n",
    "# On Windows\n",
    "scripts\\setup_hooks.bat\n",
    "\n",
    "# On Mac/Linux\n",
    "./scripts/setup_hooks.sh\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
